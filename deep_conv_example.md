# （深度）转化模型的样本方案

在信息流类的互联网产品中，存在着各种各样的`转化`现象。比如用户点击了文章题目进入详情页，再比如用户对带货视频产生了购买行为，亦或是用户后续会花比较长的时间来看一本小说或是一部电视剧，等等。虽然这些转化行为背后的产品逻辑与商业故事各有不同甚至大相径庭，但是在算法建模上它们都可以被建模为`转化`。这些转化行为的发生是带有很强的随机性的，但其中又有明显的规律，这种规律主要来人类行为中的四个特点：

1. 高热：指有一些优质的item或者更容易诱导用户产生某些转化行为的item，无论曝光给哪种用户，往往都会有比较高的转化率。比如标题党会诱导用户点击标题，又比如故意让评论对对联的帖子会天然评论率就会很高，这样的看起来像是作弊的例子不胜枚举。但也有一些转化类型，如果一个item能做到高热，那么基本能够认为它更为优质，比如停留时长，或是item留存。
2. 个性化：指不同的用户群体会定义不同的高热转化标准。通过观察可以发现一些用户在体育类item上的某些转化率明显比他们在历史类item上的这种转化率要高很多。这可以对应所谓`长期兴趣`。
3. 用户惯性：
4. 位置偏倚：

基于上述规律性的特点，我们可以从`挑选`的角度来将历史上转化能力更优的item尽量优先的曝光给用户，或者是带有某些历史上转化能力更优的item所普遍带有的特征的item尽量优先的曝光给用户。

面对转化行为的建模，我们必须要充分理解其随机性。同样是用基于embedding和MLP的监督学习模型，用于分类色情文本的分类器模型基本可以认为其groundtruth是确定不变的，并且几乎所有的信号都是可以被系统采集到并且可以作为训练特征的，但用于排序item的ctr模型，用户的groundtruth却受各种因素影响，其中绝大部分是系统不可能捕捉到的。

本文的转化建模基于以下几个设定：

1. 推荐本身是`point wise`的，而非`pair wise`，实际在生产环境中，`pair wise`的建模有明显收益的可能性比较小。
2. 推荐本身是`point wise`的，而非`list wise`，而对于`list wise`多作用于`重排阶段`，本文讨论的转化建模主要发生在`召回阶段`或`排序阶段`，它们的特点是具有十足的“选择”意味，而重排则更多是为了解决上文中的`位置偏移`所做的消偏工作，这与转化的建模没有直接关系。


一个`转化`的格式如下所示

## 转化与样本的关系

```protobuf
message Conv {
    ConvType conv_type = 1;
    int64 conv_time = 2;
    float conv_value = 3;
    repeated int64 conv_item_id = 4;

    repeated Attr attr = 101;
}
```

转化`Conv`会作为一个样本`Example`的一个重要成员属性。所谓样本拼接程序`deep_conv`，就是为`Example`填充不同的`Conv`属性，这些`Conv`属性在后续的使用主要有两种：

1. 直接提供给训练器`trainer`程序，并被训练脚本转化为label。
2. 被更深层的`deep_conv`使用，产出`更深度`的转化样本。

在上述的转化定义中，`Conv`需要记录至少四种信息

一个训练样本格式为：

```protobuf
message Meta {
    int64 user_id = 1;
    int64 item_id = 2;
    // ...
    repeated Conv conv = 20;
}
message Example {
    Meta meta = 1;
    repeated float label = 2;
    repeated int64 feature_id = 3;
    repeated Embedding embedding = 4;
}
```

为了缓存`ctr_example`或是`conv`，我们需要设计redis中value的结构，可想而知，它也应该用一个protobuf的message来描述，且value是序列化后的二进制值。像redis这种远程字典服务，其value最大可支持到1G，这对于样本或者是转化信息而言，显然是非常足够的。

```protobuf
message Wrapper {
    string key = 1;
    repeated ConvType conv_type = 2;
    repeated Example example = 3;
    repeated Conv conv = 4;
}
```

一个深度转化

### 不必要的redis访问

如果是留存目标，在同一天内有一个conv出现就可以判定其转化为正例了，没有必要对所有的conv都访问一次其对应key的redis。这时可以在内存里构建一个字典结构来保存不需要访问的key与conv_type。

## 信息流类产品中常见的体裁

### 文章/咨询/新闻

### 微博式帖子

### 知乎式问答的问题

### 知乎式问答的回答

### b站式中短视频

### 抖音式短视频

### 神评

### 小说的一本

### 小说的一章

### 电影

### 连续剧的整部剧

### 连续剧的一集

### 综艺的一期

### 综艺的一套

### 线索

### 普通评论

普通评论有如下几个特点：

1. 数量巨大
2. 不同文章下的评论不能混推，只能在同一个文章的评论区下进行排序




## 普通转化案例

普通转化是相对于深度转化而言的，一般来说，在ctr正例判定后

### item停留时长

### 进评论区

### 发表评论

### 点击关注

### 分享内容

### 点击传送门

这种传送门的产品形式十分多见，下面举几个例子：

1. 影视拆条或是某些IP的盘点混剪类的中短视频，可以传送跳转到其对应的版权视频上。比如《钢铁侠的40款战衣》可以跳转到《钢铁侠》这部电影上。
2. 微信读书类的app中会有一些类似社区的功能

### 进店/点击商品链接

进店是一个普通转化，而其后续可能会发生的购买行为则是一个深度转化，这主要是因为用户会存在一个购买决策的时间。不过事实上，在信息流类产品中，购买行为的决策时间很短，可能有六七成的购买行为是发生在改次阅读返回列表页之前

### 列表页时长

这主要是



## 深度转化案例

所谓的深度转化有两种类型，一种是时间窗口很深，另一种是建模层级很深。

### 带商品卡图文等的购买行为

### 关注后效果

### 评论后回复

### 作者对评论的点赞

### 阅读问题后的回答转化

### 阅读/播放后的主动复看

### 体裁留存

### Item留存

### 审核状态拼接

### Sug再搜索

### 版权视频的演员与编剧





### 算一算常用的转化模型中的优化参数
模型中的embedding都以`k=4`来描述，实际上k是一个超参，模型效果一般对它不会特别的敏感。

## 对比不同的item_type

在Meta的定义中就有item_type，表示的被推荐内容的类型。这个类型的划分是根据

## 转化结果作为特征

从本节开始，我们讨论将转化样本以特征的形式供给给转化模型的方法。


## 名词解释
### 监督学习中的embedding

### 监督学习中的MLP

### 监督学习中的AUC